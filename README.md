
# üöÄ Projeto DevOps - FastAPI com Jenkins, Docker e Kubernetes

Este projeto demonstra a constru√ß√£o de uma esteira CI/CD usando uma API em FastAPI, conteineriza√ß√£o com Docker, e orquestra√ß√£o via Kubernetes, com Jenkins como ferramenta central de automa√ß√£o.

---

## üß± Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ backend
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ .dockerignore
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...
````

---

## ‚úÖ Fase 1 - Prepara√ß√£o

- ‚úÖ C√≥digo da API clonado e testado localmente
- ‚úÖ Reposit√≥rio GitHub privado criado
- ‚úÖ Execu√ß√£o local via `uvicorn` validada:

```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --reload
````

* üîó Acesso em: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## üê≥ Fase 2 - Conteineriza√ß√£o com Docker

### üìÑ Dockerfile

O Dockerfile est√° localizado em `/backend` e define a build da API com base no Python 3.9:

```Dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### üìÇ .dockerignore

```dockerignore
__pycache__/
*.pyc
.git
*.md
```

### üß™ Teste local do container

```bash
cd backend
docker build -t meu-backend:latest .
docker run -d -p 8000:8000 meu-backend:latest
```

Acesso: [http://localhost:8000/docs](http://localhost:8000/docs)

### ‚òÅÔ∏è Push no Docker Hub

```bash
docker tag meu-backend:latest seuusuario/fastapi-app:latest
docker push seuusuario/fastapi-app:latest
```

üîó Docker Hub: [https://hub.docker.com/r/seuusuario/projeto-devops](https://hub.docker.com/r/seuusuario/projeto-devops)

---

## üöÄ Fase 3 ‚Äì Deploy manual no Kubernetes

Nesta fase, a aplica√ß√£o FastAPI foi implantada em um cluster Kubernetes local (Rancher Desktop), utilizando recursos `Deployment`, `Service` e `Ingress`.

---

### üìÅ Estrutura de Arquivos YAML

Os manifests est√£o organizados em `./k8s/`:

- `projeto-devops.yaml`: cont√©m o `Deployment` e o `Service`
- `ingress.yaml`: exp√µe a aplica√ß√£o via dom√≠nio interno com Traefik

---

### üîß Recursos Criados

#### üì¶ Deployment

- Nome: `projeto-devops`
- Replicas: `2`
- Imagem: `viniciusemanuelds/projeto-devops:latest`
- Porta container: `8000`
- Labels: `app: fastapi`, `name: projeto-devops`
- Namespace: `devops`

#### üåê Service

- Tipo: `ClusterIP`
- Porta: `80 ‚Üí 8000`
- Seleciona o app `fastapi`

#### üåç Ingress (Traefik)

- Host: `projeto.localhost`
- Path: `/ ‚Üí service/projeto-devops`
- Tipo: `Ingress`
- Controlador: Traefik (padr√£o no Rancher Desktop)

---

### üõ† Comandos Utilizados

```bash
# Criar namespace
kubectl create namespace devops

# Aplicar deployment e service
kubectl apply -f ./k8s/projeto-devops.yaml -n devops

# Aplicar Ingress
kubectl apply -f ./k8s/ingress.yaml -n devops

# Verificar recursos
kubectl get all -n devops
kubectl get ingress -n devops


‚úÖ Verifica√ß√£o do funcionamento
A aplica√ß√£o pode ser acessada via navegador:

üîó http://projeto.localhost/docs

O Swagger da API FastAPI √© carregado com sucesso, confirmando o roteamento via Traefik.

üß† Observa√ß√µes T√©cnicas
O uso de Ingress permite simular uma arquitetura real com DNS e proxy reverso

A tag da imagem deve ser definida diretamente (latest, v1, etc.) ‚Äî n√£o suportado {{tag}}

As labels de Deployment.selector.matchLabels e Pod.metadata.labels precisam coincidir

Evitou-se o uso de NodePort para manter boa pr√°tica de exposi√ß√£o via Ingress Controller

Perfeito. Aqui est√° a documenta√ß√£o completa e profissional da **Fase 4 ‚Äì Jenkins: Build + Push + Deploy**, incluindo um **guia b√°sico de instala√ß√£o e configura√ß√£o do Jenkins** com foco pr√°tico e reprodut√≠vel.

---

````markdown
## üîß Fase 4 ‚Äì Jenkins CI/CD (Build + Push + Deploy)

Nesta fase, foi implementada uma pipeline completa de CI/CD usando **Jenkins**, que automatiza o build da imagem Docker, faz o push para o Docker Hub e aplica o deploy no cluster Kubernetes local via `kubectl`.

---

### üì¶ Estrutura geral da esteira

- **Pipeline Declarativa** (`Jenkinsfile`) com 3 stages:
  1. **Build** da imagem Docker com `docker.build`
  2. **Push** para Docker Hub (`latest` e `${BUILD_ID}`)
  3. **Deploy** autom√°tico no cluster Kubernetes (`kubectl apply`)
- Substitui√ß√£o din√¢mica da tag da imagem no manifesto YAML (`{{tag}}`)
- Deploy realizado em namespace isolado: `devops`

---

## üß≠ Etapas de Instala√ß√£o e Configura√ß√£o do Jenkins

### 1. Instala√ß√£o (Windows com WSL + Rancher Desktop)

- Instale o Jenkins localmente (via `.war` ou MSI)
- Crie um agente Jenkins conectado ao WSL com label `WSL_Ubuntu`
- D√™ permiss√£o para que o agente use Docker local
- Instale os plugins essenciais:
  - **Docker Pipeline**
  - **Kubernetes CLI Plugin**
  - **Git Plugin**
  - (opcional) **ChuckNorris Plugin**

---

### 2. Configura√ß√£o necess√°ria

- **Docker Hub Credentials**:
  - Tipo: `Username with Password`
  - ID: `dockerhub`

- **GitHub Credentials**:
  - Tipo: `SSH Username with Private Key`
  - ID: `git`

- **Kubeconfig Credentials**:
  - Tipo: `Kubeconfig File`
  - ID: `kubeconfig`

- **Agente com Docker configurado** (dentro do WSL)
- Label: `WSL_Ubuntu`

---

## üß± Jenkinsfile

```groovy
pipeline {
    agent { label 'WSL_Ubuntu' }

    stages {
        stage('Build do Backend') {
            steps {
                script {
                    dockerapp = docker.build("viniciusemanuelds/projeto-devops:${env.BUILD_ID}", '-f ./src/backend/Dockerfile ./src/backend')
                }
            }
        }

        stage('Push da imagem') {
            steps {
                script {
                    docker.withRegistry('https://registry.hub.docker.com', 'dockerhub') {
                        dockerapp.push('latest')
                        dockerapp.push("${env.BUILD_ID}")
                    }
                }
            }
        }

        stage('Deploy no Kubernetes') {
            environment {
                tag_version = "${env.BUILD_ID}"
            }
            steps {
                withKubeConfig([credentialsId: 'kubeconfig']) {
                    sh 'sed -i "s/{{tag}}/$tag_version/g" ./k8s/projeto-devops.yaml'
                    sh 'kubectl apply -f ./k8s/projeto-devops.yaml -n devops'
                }
            }
        }
    }

    post {
        failure {
            echo 'Build falhou. Mas Chuck Norris nunca falha.'
        }
    }
}
````

---

### üìÑ Estrutura do manifesto Kubernetes (`projeto-devops.yaml`)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: projeto-devops
  namespace: devops
spec:
  replicas: 2
  selector:
    matchLabels:
      app: fastapi
  template:
    metadata:
      labels:
        app: fastapi
    spec:
      containers:
      - name: projeto-devops
        image: viniciusemanuelds/projeto-devops:{{tag}}
        ports:
        - containerPort: 8000
---
apiVersion: v1
kind: Service
metadata:
  name: projeto-devops
  namespace: devops
spec:
  selector:
    app: fastapi
  ports:
  - port: 80
    targetPort: 8000
  type: ClusterIP
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: projeto-devops-ingress
  namespace: devops
  annotations:
    traefik.ingress.kubernetes.io/router.entrypoints: web
spec:
  rules:
    - host: projeto.localhost
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: projeto-devops
                port:
                  number: 80
```

---

## ‚úÖ Resultado final

Ap√≥s cada `git push` ou build manual:

* A imagem da API √© reconstru√≠da e publicada no Docker Hub
* A tag `latest` e o n√∫mero do build (`:5`, `:6`, etc.) s√£o atribu√≠dos
* O cluster Kubernetes aplica o novo deploy com a imagem atualizada
* A aplica√ß√£o est√° acess√≠vel via:

üîó [http://projeto.localhost/docs](http://projeto.localhost/docs)

---

## üîê Desafio Extra: Scan de Vulnerabilidades com Trivy

### üéØ Objetivo

Integrar o **Trivy** √† pipeline Jenkins para escanear automaticamente as imagens Docker geradas e **bloquear o deploy caso existam vulnerabilidades CR√çTICAS corrig√≠veis**.

---

### ‚öôÔ∏è Etapas da Implementa√ß√£o

1. **Instala√ß√£o do Trivy**
   O Trivy foi utilizado via container, sem instala√ß√£o local, usando o seguinte comando base:

   ```bash
   docker run --rm \
     -v /var/run/docker.sock:/var/run/docker.sock \
     aquasec/trivy image nome-da-imagem
   ```

2. **Inclus√£o na pipeline Jenkins**
   Um novo `stage` foi adicionado no `Jenkinsfile`, antes do deploy, contendo:

   ```groovy
   stage('Scan de Vulnerabilidades com Trivy') {
       steps {
           script {
               def image = "viniciusemanuelds/projeto-devops:${env.BUILD_ID}"
               echo "üîç Escaneando a imagem ${image} com Trivy..."

               def exitCode = sh(
                   script: """#!/bin/bash
                   docker run --rm \
                   -v /var/run/docker.sock:/var/run/docker.sock \
                   -v \$PWD:/root/.cache/ \
                   aquasec/trivy \
                   image ${image} \
                   --severity CRITICAL \
                   --ignore-unfixed \
                   --exit-code 1 \
                   --format table \
                   --output trivy-report.txt
                   """,
                   returnStatus: true
               )

               if (exitCode != 0) {
                   error "‚ùå Vulnerabilidades CR√çTICAS (com corre√ß√£o) encontradas na imagem Docker! Build bloqueado. Veja trivy-report.txt."
               } else {
                   echo "‚úÖ Nenhuma vulnerabilidade cr√≠tica (corrig√≠vel) encontrada na imagem."
               }
           }
       }
   }
   ```

3. **Pol√≠tica de Seguran√ßa adotada**

   * **Gravidade avaliada:** Apenas CVEs com severidade `CRITICAL`;
   * **Crit√©rio de bloqueio:** Apenas se houver **patch dispon√≠vel**;
   * **Relat√≥rio gerado:** `trivy-report.txt`.

---

### üß† Decis√£o Arquitetural

> **Optamos por manter a imagem base `python:3.9-slim`, mesmo apresentando uma vulnerabilidade cr√≠tica (`CVE-2023-45853`) no pacote `zlib1g`.**
> Esta decis√£o foi baseada em dois fatores:
>
> 1. A vulnerabilidade est√° marcada como `will_not_fix` pela equipe mantenedora do pacote no Debian.
> 2. O impacto no contexto do projeto √© m√≠nimo e sem exposi√ß√£o direta ‚Äî portanto, aceitamos o risco controlado.
>
> A op√ß√£o `--ignore-unfixed` do Trivy garante que apenas vulnerabilidades com corre√ß√£o dispon√≠vel interrompam o pipeline.

---

Se quiser, posso gerar essa se√ß√£o j√° formatada para o `README.md` tamb√©m. Deseja isso?

√ìtimo. Aqui est√° a documenta√ß√£o da **Fase Extra: Webhook com GitHub e Ngrok**, no padr√£o das fases anteriores:

---

## üîÅ Fase Extra: Integra√ß√£o com Webhook GitHub + Ngrok

### Objetivo

Automatizar a execu√ß√£o da pipeline Jenkins sempre que houver um push no reposit√≥rio GitHub, mesmo com o Jenkins sendo executado localmente.

---

### üß∞ Pr√©-Requisitos

* Jenkins rodando localmente (porta `8081`)
* Conta no [Ngrok](https://ngrok.com/)
* Reposit√≥rio GitHub j√° configurado com o Jenkinsfile

---

### ‚öôÔ∏è Etapas da Configura√ß√£o

#### 1. Instalar e autenticar o Ngrok (Windows)

```bash
winget install Ngrok.Ngrok
ngrok config add-authtoken <SEU_TOKEN_NGROK>
```

#### 2. Expor Jenkins via Ngrok

```bash
ngrok http 8081
```

> Guarde o endere√ßo gerado, ex: `https://8cd4-2804-xyz.ngrok.io`

---

#### 3. Configurar Webhook no GitHub

* Acesse seu reposit√≥rio ‚Üí ‚öôÔ∏è Settings ‚Üí Webhooks ‚Üí **Add webhook**
* **Payload URL:**
  `https://<NGROK_URL>/github-webhook/`
  Exemplo: `https://8cd4-2804-xyz.ngrok.io/github-webhook/`
* **Content type:** `application/json`
* **Secret:** (deixe vazio ou use um token simples)
* **Just the push event** (marcado)
* Clique em **Add webhook**

---

#### 4. Configurar o Job no Jenkins

* Em **Pipeline ‚Üí Configure**
* V√° at√© **Build Triggers**

  * Marque: `GitHub hook trigger for GITScm polling`

---

### üì¶ Entreg√°vel

* Push no GitHub aciona automaticamente o Jenkins, que realiza build, push da imagem e deploy no Kubernetes.

---

> üí° **Decis√£o t√©cnica**
>
> A exposi√ß√£o do Jenkins foi feita via **Ngrok**, evitando configura√ß√µes complexas de rede ou servidores externos. Essa abordagem √© suficiente para ambientes locais e testes de integra√ß√£o cont√≠nua.

---

Pronto para o pr√≥ximo desafio extra?

