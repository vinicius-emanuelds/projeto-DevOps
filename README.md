# ‚ôæÔ∏èProjeto DevOps: Guia Definitivo de uma Pipeline CI/CD Completa

Este reposit√≥rio √© a documenta√ß√£o da minha jornada construindo uma esteira de Integra√ß√£o e Entrega Cont√≠nua (CI/CD) do zero, um projeto que realizei no programa **Scholarship da CompassUOL**.

Minha inten√ß√£o aqui foi ir al√©m de um simples "como fazer". Este √© um guia detalhado que explora n√£o apenas o "o qu√™", mas o "porqu√™" de cada ferramenta, cada comando e cada decis√£o de arquitetura. O objetivo de uma pipeline CI/CD √© criar uma ponte automatizada, segura e eficiente entre o c√≥digo e o usu√°rio final, e cada linha deste projeto foi pensada para entender e dominar esse fluxo.

## Navega√ß√£o
- [‚ôæÔ∏èProjeto DevOps: Guia Definitivo de uma Pipeline CI/CD Completa](#Ô∏èprojeto-devops-guia-definitivo-de-uma-pipeline-cicd-completa)
  - [Navega√ß√£o](#navega√ß√£o)
  - [Vis√£o Geral e Arquitetura](#vis√£o-geral-e-arquitetura)
  - [Fase 1: Prepara√ß√£o do Ambiente de Desenvolvimento](#fase-1-prepara√ß√£o-do-ambiente-de-desenvolvimento)
  - [Fase 2: Containeriza√ß√£o Profissional com Docker](#fase-2-containeriza√ß√£o-profissional-com-docker)
    - [O Dockerfile Otimizado](#o-dockerfile-otimizado)
    - [O `.dockerignore`](#o-dockerignore)
  - [Fase 3: Deploy no Kubernetes: A Forma Manual](#fase-3-deploy-no-kubernetes-a-forma-manual)
    - [A Arquitetura do Deploy](#a-arquitetura-do-deploy)
  - [Fase 4 e 5: Automa√ß√£o com Jenkins e Pipeline as Code](#fase-4-e-5-automa√ß√£o-com-jenkins-e-pipeline-as-code)
    - [Configura√ß√£o do Jenkins](#configura√ß√£o-do-jenkins)
    - [O Jenkinsfile Detalhado](#o-jenkinsfile-detalhado)
- [Desafios Extras: Construindo uma Pipeline de N√≠vel Profissional](#desafios-extras-construindo-uma-pipeline-de-n√≠vel-profissional)
  - [DevSecOps 1: An√°lise Est√°tica de C√≥digo (SAST) com SonarQube](#devsecops-1-an√°lise-est√°tica-de-c√≥digo-sast-com-sonarqube)
  - [DevSecOps 2: An√°lise de Vulnerabilidades com Trivy](#devsecops-2-an√°lise-de-vulnerabilidades-com-trivy)
  - [Automa√ß√£o do Fluxo: Webhooks para GitHub (com Smee.io) e Notifica√ß√µes no Discord](#automa√ß√£o-do-fluxo-webhooks-para-github-com-smeeio-e-notifica√ß√µes-no-discord)
  - [Infraestrutura como C√≥digo Avan√ßada: Deploy com Helm](#infraestrutura-como-c√≥digo-avan√ßada-deploy-com-helm)
  - [Conclus√£o e Principais Aprendizados](#conclus√£o-e-principais-aprendizados)

<br>

---

## Vis√£o Geral e Arquitetura

O fluxo de trabalho automatizado (pipeline) que constru√≠ segue os seguintes passos:

1. O c√≥digo de uma API em **FastAPI** √© enviado (`push`) para o **GitHub**.
2. Um webhook do **Smee.io** notifica meu **Jenkins** local sobre a altera√ß√£o.
3. O **Jenkins** inicia a pipeline, que primeiro analisa o c√≥digo com **SonarQube**.
4. Em seguida, a pipeline constr√≥i uma imagem **Docker** da aplica√ß√£o.
5. A imagem √© escaneada em busca de vulnerabilidades pelo **Trivy**.
6. Se segura, a imagem √© enviada para o **Docker Hub**.
7. O **Helm** √© acionado para fazer o deploy da nova vers√£o no cluster **Kubernetes**.
8. Ao final, uma notifica√ß√£o de sucesso ou falha √© enviada para um canal no **Discord**.

```mermaid
flowchart

A[ALtero o reposit√≥rio local com o c√≥digo API] --> B[Envio, via push, para o GitHub]
B --> C[Webhook com Smee.io notifica o Jenkins do novo commit]
C --> D[O Jenkins inicia a pipeline, analisando o c√≥digo com SonarQube]
D --> K[O relat√≥rio do SonarQube √© exibido no Console Output]
K --> E
D --> E[Sucesso! A pipeline constr√≥i a imagem Docker da aplica√ß√£o]
E --> G[A imagem √© escaneada pelo Trivy]
G --> L[Encontradas vulnerabilidades CR√çTICAS com corre√ß√£o dispon√≠vel]
L --> F[Falha! O deploy √© interrompido e o log √© exibido no Console Output]
G --> H[Sem vulnerabilidades! A imagem √© enviada para o Docker Hub]

H --> I[O Helm √© acionado para fazer o deploy da nova vers√£o no cluster Kubernetes]
I --> J[Atrav√©s do NGrok, uma notifica√ß√£o de Sucesso ou Falha √© disparada para o Discord]
F --> J
```

[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)

<br>

---


## Fase 1: Prepara√ß√£o do Ambiente de Desenvolvimento

A base de qualquer projeto de automa√ß√£o √© um ambiente local funcional e bem configurado.

1. **C√≥digo e Versionamento**: O c√≥digo da API foi versionado com Git e hospedado no GitHub, essencial para a CI.
2. **Valida√ß√£o Local da API**: Para garantir que a aplica√ß√£o funcionava antes de qualquer outra coisa, executei os seguintes passos:

   ```bash
   # Navegar para a pasta do backend
   cd backend

   # Criar um ambiente virtual. Esta √© uma pr√°tica essencial em Python para isolar
   # as depend√™ncias de cada projeto.
   python -m venv venv

   # Ativar o ambiente virtual
   source venv/bin/activate

   # Instalar as bibliotecas Python necess√°rias para a API
   pip install -r requirements.txt

   # Iniciar o servidor de desenvolvimento.
   # Uvicorn √© um servidor ASGI (Asynchronous Server Gateway Interface),
   # necess√°rio para rodar frameworks ass√≠ncronos como o FastAPI.
   # A flag --reload √© indispens√°vel para desenvolvimento, pois reinicia
   # o servidor automaticamente sempre que um arquivo .py √© alterado.
   uvicorn main:app --reload
   ```

   Com a API rodando e acess√≠vel em `http://127.0.0.1:8000/docs`, chegou a hora de  prosseguir.


[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)

<br>

---


## Fase 2: Containeriza√ß√£o Profissional com Docker

Containerizar n√£o √© apenas rodar um `docker build`. √â sobre criar imagens otimizadas, seguras e pequenas.

### O Dockerfile Otimizado

Criei um `Dockerfile` pensando em performance e no cache de camadas do Docker.

```dockerfile
# /backend/Dockerfile

# Etapa 1: Imagem Base
# Utilizei a imagem 'python:3.9-slim' por ser uma vers√£o enxuta,
# o que diminui a superf√≠cie de ataque e o tamanho final da imagem.
FROM python:3.9-slim

# Etapa 2: Diret√≥rio de Trabalho
# Define o diret√≥rio de trabalho padr√£o. Isso √© uma boa pr√°tica para
# n√£o poluir o diret√≥rio raiz do container.
WORKDIR /app

# Etapa 3: Instala√ß√£o de Depend√™ncias com otimiza√ß√£o de cache
# Copio inicialmente apenas o requirements.txt para aproveitar o cache do Docker.
# Altera√ß√µes no c√≥digo-fonte n√£o afetam esta camada, otimizando futuros builds.
COPY requirements.txt .

# Atualizo o sistema e instalo as depend√™ncias Python.
RUN apt-get update && apt-get upgrade -y && apt-get clean && \
    pip install --no-cache-dir -r requirements.txt

# Etapa 4: C√≥pia do C√≥digo
# Agora copio o resto do c√≥digo. Qualquer altera√ß√£o aqui invalidar√°
# apenas o cache desta camada e das subsequentes.
COPY . .

# Etapa 5: Comando de Execu√ß√£o
# Exp√µe a aplica√ß√£o na porta 8000 e no host 0.0.0.0,
# que √© essencial para que a aplica√ß√£o seja acess√≠vel de fora do container.
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### O `.dockerignore`

Para evitar que arquivos desnecess√°rios (como ambientes virtuais, cache do Python ou o pr√≥prio diret√≥rio `.git`) fossem copiados para a imagem, criei um arquivo `.dockerignore`.

```dockerignore
__pycache__/
*.pyc
.git
.venv
*.md
```

Com tudo pronto, constru√≠ e publiquei a imagem no Docker Hub.


[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)

<br>

---


## Fase 3: Deploy no Kubernetes: A Forma Manual

Antes de automatizar com o Jenkins, fiz o deploy manualmente para entender profundamente os recursos do Kubernetes.

### A Arquitetura do Deploy

O fluxo de uma requisi√ß√£o at√© a aplica√ß√£o dentro do Kubernetes funciona assim:

`Usu√°rio Externo ‚Üí Ingress ‚Üí Service ‚Üí Pod (Container)`

* **Deployment**: √â a receita que diz ao Kubernetes como rodar minha aplica√ß√£o: qual imagem usar (`viniciusemanuelds/projeto-devops`) e quantas r√©plicas (`replicas: 2`) manter sempre em execu√ß√£o. A se√ß√£o `selector.matchLabels` √© crucial, pois ela conecta o Deployment aos Pods que ele deve gerenciar.
* **Service**: Cria um ponto de acesso interno e est√°vel (um DNS interno) para os Pods. Os IPs dos Pods mudam. O Service prov√™ um endere√ßo fixo. Usei o tipo `ClusterIP`, que o torna acess√≠vel apenas de dentro do cluster.
* **Ingress**: √â o porteiro do cluster. Ele exp√µe rotas HTTP/HTTPS para os Services. Optei pelo Ingress em vez do `NodePort` porque ele √© muito mais poderoso: permite roteamento baseado em dom√≠nio (`projeto.localhost`), centraliza o gerenciamento de SSL e se integra a controladores de tr√°fego avan√ßados como o Traefik (padr√£o no Rancher Desktop).

Apliquei os manifestos no cluster com `kubectl apply -f <projeto-devops.yaml> -n devops`, e a aplica√ß√£o ficou dispon√≠vel.


[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)

<br>

---


## Fase 4 e 5: Automa√ß√£o com Jenkins e Pipeline as Code

Aqui, o trabalho manual acaba e a automa√ß√£o come√ßa. O objetivo √© tratar a pipeline como c√≥digo (`Pipeline as Code`), versionando-a junto com a aplica√ß√£o no `Jenkinsfile`.

### Configura√ß√£o do Jenkins

A prepara√ß√£o do Jenkins envolveu:

1. **Instala√ß√£o e Agentes**: Instalei o Jenkins e configurei um agente no WSL2 para ter um ambiente Linux limpo e com acesso nativo ao Docker.
2. **Plugins**: Instalei os plugins essenciais: `Docker Pipeline`, `Kubernetes CLI Plugin`, `Git Plugin`, `SonarQube Scanner` e `Discord Notifier`.
3. **Credenciais**: Cadastrei de forma segura as credenciais do GitHub (Chave SSH), Docker Hub (Usu√°rio/Senha), SonarQube (Token) e Kubeconfig.

### O Jenkinsfile Detalhado

```groovy
//Jenkisfile
pipeline {
    agent {
        label 'WSL_Ubuntu'
    }

    tools {
        git 'linux-git'
    }

    stages {
        stage('Build do Backend') {
            steps {
                script {
                    dockerapp = docker.build("viniciusemanuelds/projeto-devops:${env.BUILD_ID}",'-f ./src/backend/Dockerfile ./src/backend')
                }
            }
        }

        stage('Push da imagem') {
            steps {
                script {
                    docker.withRegistry('https://registry.hub.docker.com', 'dockerhub') {
                        dockerapp.push('latest')
                        dockerapp.push("${env.BUILD_ID}")
                    }
                }
            }
        }

        stage('Deploy no Kubernetes') {
            environment {
                tag_version = "${env.BUILD_ID}"
            }
            steps {
                withKubeConfig([credentialsId: 'kubeconfig']) {
                    sh 'sed -i "s/{{tag}}/$tag_version/g" ./k8s/projeto-devops.yaml'
                    sh 'kubectl apply -f ./k8s/projeto-devops.yaml -n devops'
                }
            }
        }
    }
}

```

* **Refer√™ncia em V√≠deo:** Para a constru√ß√£o e deploy dessa pipeline, esse v√≠deo foi indispens√°vel para clarear o passo a passo: [O que √© Jenkins | Guia pr√°tico para come√ßar com Jenkins](https://www.youtube.com/watch?v=mvtVL5eivzo&t).


[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)

<br>

---


# Desafios Extras: Construindo uma Pipeline de N√≠vel Profissional

Com a base s√≥lida, adicionei etapas avan√ßadas para simular um ambiente DevSecOps real.

<br>

## DevSecOps 1: An√°lise Est√°tica de C√≥digo (SAST) com SonarQube

O SonarQube olha para o *meu* c√≥digo. Ele faz uma An√°lise Est√°tica de Seguran√ßa da Aplica√ß√£o (SAST) para encontrar bugs, "code smells" (m√°s pr√°ticas) e vulnerabilidades como inje√ß√£o de SQL ou senhas hard-coded.

**Implementa√ß√£o:**

1. **SonarQube Server**: Subi o SonarQube via Docker: `docker run -d --name sonarqube -p 9000:9000 sonarqube:lts-community`.
2. **Configura√ß√£o no Jenkins**: Configurei a URL do servidor e o token de autentica√ß√£o no Jenkins.
3. **Est√°gio na Pipeline**: Adicionei um est√°gio para executar a an√°lise antes de construir a imagem.

<!-- end list -->

```groovy
stage('An√°lise com SonarQube') {
	steps {
 		withSonarQubeEnv('sonar-local') {
			sh """
			sonar-scanner \
				-Dsonar.projectKey=projeto-devops \
				-Dsonar.sources=. \
				-Dsonar.host.url=http://localhost:9000 \
				-Dsonar.token=${env.SONAR_TOKEN} \
				-Dsonar.python.version=3.9 \
				-Dsonar.exclusions=trivy/**
			"""
		}
	}
}
```

**Problemas Resolvidos:** A integra√ß√£o teve seus desafios, como erros de conex√£o (`host.docker.internal` n√£o funciona bem no WSL2, usei `localhost`) e a necessidade de configurar o `sonar-scanner` manualmente no agente Jenkins.

[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)

<br>


## DevSecOps 2: An√°lise de Vulnerabilidades com Trivy

**Por qu√™?** Enquanto o SonarQube olha para o *meu* c√≥digo, o Trivy olha para as depend√™ncias. Uma aplica√ß√£o pode ser funcional, mas suas depend√™ncias podem conter falhas de seguran√ßa conhecidas (CVEs). Escanear a imagem Docker √© um passo cr√≠tico de "shift-left security", ou seja, trazer a seguran√ßa para o in√≠cio do processo.

**Implementa√ß√£o:** Adicionei um est√°gio no Jenkins que roda o Trivy logo ap√≥s o build da imagem.

```groovy
        stage('Scan de Vulnerabilidades com Trivy') {
            steps {
                script {
                    def image = "viniciusemanuelds/projeto-devops:${env.BUILD_ID}"
                    echo "Escaneando a imagem ${image}..."

                    def exitCode = sh(
                        script: """#!/bin/bash
                        docker run --rm \
                        -v /var/run/docker.sock:/var/run/docker.sock \
                        -v \$PWD:/root/.cache/ \
                        aquasec/trivy \
                        image ${image} \
                        --severity CRITICAL \
                        --ignore-unfixed \
                        --exit-code 1 \
                        --format table \
                        --output trivy-report.txt
                        """,
                        returnStatus: true
                    )

                    if (exitCode != 0) {
                        error "‚ùå Vulnerabilidades CR√çTICAS encontradas na imagem Docker! Build bloqueado."
                    } else {
                        echo "‚úÖ Nenhuma vulnerabilidade cr√≠tica encontrada."
                    }
                }
            }
        }

```

> **Decis√£o Arquitetural Importante:** Ao escanear, o Trivy encontrou uma vulnerabilidade cr√≠tica (`CVE-2023-45853`) no pacote `zlib1g` da imagem base. No entanto, a equipe do Debian marcou-a como `will_not_fix` (n√£o ser√° corrigida). Em um cen√°rio real, isso exigiria uma an√°lise de risco. Para este projeto, decidi aceitar o risco, pois o impacto era m√≠nimo, e usei a flag `--ignore-unfixed` para que o Trivy s√≥ bloqueasse a pipeline por falhas que tivessem uma corre√ß√£o dispon√≠vel.

[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)

<br>


## Automa√ß√£o do Fluxo: Webhooks para GitHub (com Smee.io) e Notifica√ß√µes no Discord

**Por qu√™?** Uma pipeline s√≥ √© verdadeiramente "cont√≠nua" se for disparada automaticamente. E para fechar o ciclo, ela deve notificar os interessados sobre seu resultado.

**Parte A: Gatilho do GitHub com Smee.io**
O desafio: meu Jenkins √© local, o GitHub n√£o consegue alcan√ß√°-lo. A solu√ß√£o: um cliente de t√∫nel/relay. Usei o **Smee.io**, uma ferramenta recomendada pelo pr√≥prio GitHub para desenvolvimento local.

1. **Criei um Canal**: Acessei [smee.io](https://smee.io) e criei um novo canal, que me deu uma URL p√∫blica √∫nica.
2. **Configurei o Webhook no GitHub**: Apontei o webhook do meu reposit√≥rio para essa URL do Smee.
3. **Rodei o Cliente Local**: No meu terminal, rodei o comando:
   `npx smee -u https://smee.io/SEU_CANAL_AQUI -t http://localhost:8080/github-webhook/`
   Este cliente ouve o canal p√∫blico do Smee e retransmite os eventos para o meu Jenkins local.

**Parte B: Notifica√ß√µes no Discord com Ngrok**

Para enviar notifica√ß√µes ao Discord diretamente do Jenkins, utilizei um webhook do Discord configurado com o servi√ßo do  **Ngrok** , permitindo expor o Jenkins rodando localmente ao ambiente externo.

1. **Webhook no Discord**
   * No canal desejado, criei um webhook pela op√ß√£o:
     * `Configura√ß√µes do canal ‚Üí Integra√ß√µes ‚Üí Webhooks ‚Üí Novo webhook`.
   * Copiei a URL gerada pelo Discord.
2. **Configura√ß√£o do Ngrok**
   * Iniciei o Ngrok para expor localmente o Jenkins na porta correta:
     `ngrok http 8081`
   * Copiei a URL p√∫blica fornecida pelo Ngrok.
3. **Uso no Jenkins**
   * Configurei a pipeline para enviar notifica√ß√µes POST para o webhook do Discord sempre que o pipeline finaliza com sucesso ou falha, utilizando a URL p√∫blica do Ngrok.

```groovy
    post {
        success {
            script {
                def chuck = chuckNorris()
                def discordWebhook = 'SUA_URL_DISCORD'
                def mensagem = """{
                    "content": "üöÄ Deploy realizado com sucesso!"
                }"""

                sh """
                curl -H "Content-Type: application/json" \
                    -X POST \
                    -d '${mensagem}' \
                    ${discordWebhook}
                """
            }
        }

        failure {
            script {
                def chuck = chuckNorris()
                def discordWebhook = 'SUA_URL_DISCORD'
                def mensagem = """{
                    "content": "‚ö†Ô∏è A pipeline falhou!"
                }"""

                sh """
                curl -H "Content-Type: application/json" \
                    -X POST \
                    -d '${mensagem}' \
                    ${discordWebhook}
                """
            }
        }
    }
}
```

[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)

<br>



## Infraestrutura como C√≥digo Avan√ßada: Deploy com Helm

**Por qu√™?** Gerenciar m√∫ltiplos arquivos YAML do Kubernetes √© dif√≠cil e propenso a erros. O Helm √© o gerenciador de pacotes do K8s, permitindo empacotar toda a aplica√ß√£o em um "Chart" reutiliz√°vel e version√°vel.

**Implementa√ß√£o:**

1. **Criei um Helm Chart**: Estruturei meus manifestos em um diret√≥rio `helm-projeto/`, usando vari√°veis de template (ex: `{{ .Values.image.tag }}`) em vez de valores fixos.
2. **Ajustei a Pipeline**: Criei um novo est√°gio que usa o comando `helm` em vez de `kubectl`.

<!-- end list -->

```groovy
stage('Deploy com Helm') {
	steps {
		withKubeConfig([credentialsId: 'kubeconfig']) {
			sh """
			helm upgrade --install devops-helm ./helm-projeto \
				--namespace devops \
				--set image.repository=${IMAGE_NAME} \
				--set image.tag=${env.BUILD_ID}
			"""
		}
	}
}
```

**Aprendizados com Helm**: O diagn√≥stico de templates com `helm template --debug` foi essencial. Enfrentei e resolvi erros comuns, como a imutabilidade do `selector` em um Deployment e a necessidade de gerenciar os releases do Helm de forma separada dos deploys manuais com `kubectl`.

* **Refer√™ncia em V√≠deo:** Para entender a estrutura de um Chart e os comandos do Helm, este v√≠deo foi um √≥timo ponto de partida: [Guia Helm: Como simplificar o deploy no Kubernetes](https://www.youtube.com/watch?v=VTQpe-ZRgsk&t).

[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)

<br>

---

## Conclus√£o e Principais Aprendizados

Esta jornada foi muito al√©m de simplesmente aprender ferramentas. Foi sobre internalizar os princ√≠pios da cultura DevOps e DevSecOps.

* **Automa√ß√£o**: Cada hora gasta automatizando uma tarefa manual √© recuperada dezenas de vezes, liberando tempo para focar em melhorias e inova√ß√£o.
* **Seguran√ßa**: Integrar Trivy e SonarQube desde o in√≠cio me provou que seguran√ßa n√£o √© uma etapa final, mas uma responsabilidade cont√≠nua e integrada ao fluxo de desenvolvimento.
* **C√≥digo**: Tratar a infraestrutura (`YAMLs`, `Helm Charts`) e a pipeline (`Jenkinsfile`) como c√≥digo tornou o sistema transparente, version√°vel e muito mais f√°cil de manter e depurar.

Este projeto solidificou minha base t√©cnica e, mais importante, a mentalidade necess√°ria para construir e manter sistemas de software modernos, resilientes e seguros.

[‚¨ÜÔ∏è Voltar ao menu](#navega√ß√£o)
